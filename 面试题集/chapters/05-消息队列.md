## 五、消息队列

**119. Kafka的架构和核心概念？**

**答案：**
**核心概念：**
- **Producer**：生产者
- **Consumer**：消费者
- **Broker**：服务器节点
- **Topic**：主题
- **Partition**：分区
- **Offset**：偏移量

**架构：**
```
Producer → Broker集群 → Consumer
           ├─ Topic1
           │  ├─ Partition0
           │  ├─ Partition1
           │  └─ Partition2
           └─ Topic2
```

**特点：**
- 高吞吐：百万级QPS
- 持久化：磁盘存储
- 分布式：水平扩展
- 顺序性：分区内有序

**120. Kafka如何保证消息不丢失？**

**答案：**
**生产者端：**
```go
// 1. 同步发送
producer.Send(msg).Get()

// 2. 异步发送+回调
producer.Send(msg, func(metadata, err) {
    if err != nil {
        // 重试或记录
    }
})

// 3. 配置acks
acks = all  // 所有副本确认
```

**Broker端：**
```properties
# 副本数
replication.factor = 3

# 最小同步副本数
min.insync.replicas = 2

# 禁用自动创建topic
auto.create.topics.enable = false
```

**消费者端：**
```go
// 手动提交offset
for msg := range consumer.Messages() {
    process(msg)
    consumer.CommitSync()  // 处理成功后提交
}
```

**121. Kafka的分区策略？**

**答案：**
**默认策略：**
```go
// 1. 指定分区
producer.Send(topic, partition, key, value)

// 2. 指定key（hash分区）
partition = hash(key) % numPartitions

// 3. 轮询（无key）
partition = (lastPartition + 1) % numPartitions
```

**自定义分区器：**
```go
type CustomPartitioner struct{}

func (p *CustomPartitioner) Partition(topic string, key, value []byte, numPartitions int32) int32 {
    // 自定义逻辑
    if isVIP(key) {
        return 0  // VIP用户专用分区
    }
    return hash(key) % numPartitions
}
```

**分区数选择：**
- 考虑吞吐量：分区数 = 目标吞吐量 / 单分区吞吐量
- 考虑消费者数：分区数 >= 消费者数
- 不宜过多：增加延迟和资源消耗

**122. 消费者组的概念？如何实现负载均衡？**

**答案：**
**消费者组：**
- 同一组内的消费者共同消费topic
- 每个分区只能被组内一个消费者消费
- 不同组独立消费

**负载均衡：**
```
Topic (4个分区)
├─ P0 → Consumer1 (Group A)
├─ P1 → Consumer2 (Group A)
├─ P2 → Consumer3 (Group A)
└─ P3 → Consumer4 (Group A)
```

**分区分配策略：**
1. **Range**：按范围分配
2. **RoundRobin**：轮询分配
3. **Sticky**：尽量保持原分配

**Rebalance：**
- 消费者加入/退出时触发
- 重新分配分区
- 期间停止消费

**123. Kafka的offset管理？**

**答案：**
**Offset类型：**
- **Current Offset**：当前消费位置
- **Committed Offset**：已提交位置
- **Log End Offset**：最新消息位置

**提交方式：**
```go
// 1. 自动提交
enable.auto.commit = true
auto.commit.interval.ms = 5000

// 2. 手动同步提交
consumer.CommitSync()

// 3. 手动异步提交
consumer.CommitAsync(func(offsets, err) {
    if err != nil {
        log.Error(err)
    }
})
```

**存储位置：**
- Kafka 0.9+：存储在__consumer_offsets topic
- 旧版本：存储在Zookeeper

**重置offset：**
```bash
# 重置到最早
kafka-consumer-groups --reset-offsets --to-earliest

# 重置到指定位置
kafka-consumer-groups --reset-offsets --to-offset 100
```

**124. 如何保证消息的顺序性？**

**答案：**
**Kafka保证：**
- 单分区内有序
- 跨分区无序

**实现方案：**
```go
// 1. 单分区（性能差）
producer.Send(topic, 0, key, value)

// 2. 相同key到同一分区
producer.Send(topic, userID, value)  // 同一用户的消息有序

// 3. 消费者单线程处理
for msg := range consumer.Messages() {
    process(msg)  // 顺序处理
}
```

**业务保证：**
```go
// 使用版本号
type Message struct {
    UserID  string
    Version int64
    Data    string
}

// 消费时检查版本
if msg.Version <= lastVersion {
    return  // 忽略旧消息
}
```

**125. 如何处理消息积压问题？**

**答案：**
**原因分析：**
1. 消费速度慢
2. 消费者故障
3. 消息量突增

**解决方案：**

**1. 增加消费者：**
```go
// 增加消费者数量（不超过分区数）
for i := 0; i < 10; i++ {
    go startConsumer()
}
```

**2. 提升消费速度：**
```go
// 批量处理
batch := []Message{}
for msg := range consumer.Messages() {
    batch = append(batch, msg)
    if len(batch) >= 100 {
        processBatch(batch)
        batch = batch[:0]
    }
}
```

**3. 增加分区：**
```bash
# 增加分区数
kafka-topics --alter --topic test --partitions 10
```

**4. 临时方案：**
```go
// 消息转存，后续处理
for msg := range consumer.Messages() {
    db.Save(msg)  // 先存储
    consumer.CommitSync()
}
```

**监控指标：**
```
Lag = Log End Offset - Current Offset
```

**126. Kafka和RabbitMQ的区别？**

**答案：**
| 特性 | Kafka | RabbitMQ |
|------|-------|----------|
| **吞吐量** | 百万级 | 万级 |
| **延迟** | 毫秒级 | 微秒级 |
| **消息顺序** | 分区内有序 | 队列内有序 |
| **持久化** | 磁盘 | 内存+磁盘 |
| **消息路由** | 简单 | 复杂（Exchange） |
| **协议** | 自定义 | AMQP |
| **适用场景** | 日志、大数据 | 业务消息 |

**选择建议：**
- **Kafka**：大数据、日志收集、流处理
- **RabbitMQ**：业务解耦、任务队列、复杂路由

**127. 如何保证消息的幂等性？**

**答案：**
**问题：**
- 网络重试导致重复消费
- Rebalance导致重复消费

**解决方案：**

**1. 唯一ID去重：**
```go
// 生产者生成唯一ID
msg := Message{
    ID:   uuid.New(),
    Data: data,
}

// 消费者去重
if redis.Exists(msg.ID) {
    return  // 已处理
}
process(msg)
redis.Set(msg.ID, 1, 24*time.Hour)
```

**2. 数据库唯一约束：**
```sql
CREATE TABLE orders (
    order_id VARCHAR(64) PRIMARY KEY,
    ...
);

-- 插入时自动去重
INSERT INTO orders VALUES (...);
```

**3. 业务幂等：**
```go
// 状态机保证幂等
if order.Status == "paid" {
    return  // 已支付，忽略
}
order.Status = "paid"
db.Update(order)
```

**4. Token机制：**
```go
// 获取token
token := getToken()

// 提交时验证token
if !validateToken(token) {
    return  // token已使用
}
process()
deleteToken(token)
```

**128. 死信队列的作用？**

**答案：**
**定义：**
无法被正常消费的消息存储的队列。

**触发条件：**
1. 消息被拒绝（reject/nack）
2. 消息过期（TTL）
3. 队列满了

**实现（RabbitMQ）：**
```go
// 声明死信交换机
ch.ExchangeDeclare("dlx", "direct", true, false, false, false, nil)

// 声明队列，绑定死信交换机
args := amqp.Table{
    "x-dead-letter-exchange": "dlx",
    "x-message-ttl":          60000,
}
ch.QueueDeclare("main_queue", true, false, false, false, args)

// 声明死信队列
ch.QueueDeclare("dead_queue", true, false, false, false, nil)
ch.QueueBind("dead_queue", "", "dlx", false, nil)
```

**Kafka实现：**
```go
// 消费失败的消息发送到死信topic
for msg := range consumer.Messages() {
    err := process(msg)
    if err != nil {
        producer.Send("dead_topic", msg)
    }
    consumer.CommitSync()
}
```

**用途：**
- 异常消息隔离
- 问题排查
- 消息重试
- 数据备份

---

