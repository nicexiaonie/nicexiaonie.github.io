[toc]

# 十、项目经验相关

## 1. 全网文本去重系统

**183. 如何设计10亿级文档库的去重系统？**

**答案：**
**架构设计：**
```
文档输入 → 特征提取 → 指纹生成 → 分布式索引 → 相似度计算 → 结果返回
         (分词/清洗)  (SimHash)   (Redis Cluster)  (MinHash)
```

**核心组件：**
1. **特征提取服务**：分词、去停用词、TF-IDF
2. **指纹生成服务**：SimHash(64位) + MinHash(128维)
3. **索引服务**：Redis Cluster(1024分片)
4. **查询服务**：分块查询 + LSH加速
5. **计算服务**：精确相似度计算

**数据流：**
```go
type Document struct {
    ID       string
    Content  string
    SimHash  uint64
    MinHash  []uint32
    Keywords []string
}

func ProcessDocument(doc Document) {
    // 1. 特征提取
    words := tokenize(doc.Content)
    keywords := extractKeywords(words, 10)

    // 2. 生成指纹
    simhash := SimHash(words)
    minhash := MinHash(words, 128)

    // 3. 存储索引
    storeToRedis(doc.ID, simhash, minhash)

    // 4. 检查重复
    duplicates := findDuplicates(simhash, minhash)
}
```

**184. 为什么选择SimHash+MinHash混合算法？**

**答案：**
**SimHash优势：**
- 快速过滤：O(1)查询
- 固定长度：64位指纹
- 海明距离：快速计算相似度

**MinHash优势：**
- 精确度高：Jaccard相似度估算
- 适合长文本：不受长度影响

**混合策略：**
```go
func HybridSearch(text string) []string {
    // 第一层：SimHash快速召回
    simhash := SimHash(text)
    candidates := simhashSearch(simhash, threshold=3)

    // 第二层：MinHash精确过滤
    minhash := MinHash(text, 128)
    results := []string{}
    for _, docID := range candidates {
        docMH := getMinHash(docID)
        if similarity(minhash, docMH) > 0.85 {
            results = append(results, docID)
        }
    }

    return results
}
```

**性能对比：**
| 方法 | 召回率 | 准确率 | QPS |
|------|--------|--------|-----|
| 仅SimHash | 95% | 75% | 8000 |
| 仅MinHash | 85% | 95% | 1000 |
| 混合算法 | 99% | 92% | 5000+ |

**185. 如何实现QPS 5000+的高并发服务？**

**答案：**
**优化策略：**

**1. 服务架构：**
```
Nginx → API Gateway → 查询服务集群(20实例) → Redis Cluster(1024分片)
                    ↓
                  缓存层(本地缓存 + Redis)
```

**2. 并发优化：**
```go
// Goroutine池
type WorkerPool struct {
    workers   int
    taskQueue chan Task
}

func (p *WorkerPool) Start() {
    for i := 0; i < p.workers; i++ {
        go p.worker()
    }
}

func (p *WorkerPool) worker() {
    for task := range p.taskQueue {
        task.Execute()
    }
}

// 批量查询
func BatchQuery(texts []string) map[string][]string {
    results := make(map[string][]string)
    var wg sync.WaitGroup

    for _, text := range texts {
        wg.Add(1)
        go func(t string) {
            defer wg.Done()
            results[t] = Query(t)
        }(text)
    }

    wg.Wait()
    return results
}
```

**3. 缓存策略：**
```go
// 三级缓存
type CacheManager struct {
    local  *lru.Cache      // 本地缓存(10000条)
    redis  *redis.Client   // Redis缓存(100万条)
    db     *Database       // 数据库
}

func (c *CacheManager) Get(key string) ([]string, error) {
    // L1: 本地缓存
    if val, ok := c.local.Get(key); ok {
        return val.([]string), nil
    }

    // L2: Redis缓存
    if val, err := c.redis.Get(key).Result(); err == nil {
        c.local.Add(key, val)
        return parseResult(val), nil
    }

    // L3: 数据库
    val, err := c.db.Query(key)
    if err == nil {
        c.redis.Set(key, val, 1*time.Hour)
        c.local.Add(key, val)
    }
    return val, err
}
```

**4. 连接池优化：**
```go
// Redis连接池
redisPool := &redis.Pool{
    MaxIdle:     100,
    MaxActive:   1000,
    IdleTimeout: 240 * time.Second,
    Dial: func() (redis.Conn, error) {
        return redis.Dial("tcp", addr)
    },
}
```

**186. 响应时间如何优化到50ms以内？**

**答案：**
**优化措施：**

**1. 索引优化：**
```go
// SimHash分块索引
func GetBlockIndexes(fingerprint uint64) []uint16 {
    return []uint16{
        uint16(fingerprint),
        uint16(fingerprint >> 16),
        uint16(fingerprint >> 32),
        uint16(fingerprint >> 48),
    }
}

// 只查询匹配的块
func FastQuery(fingerprint uint64) []string {
    blocks := GetBlockIndexes(fingerprint)
    candidates := make(map[string]bool)

    // 并发查询4个块
    var wg sync.WaitGroup
    for _, block := range blocks {
        wg.Add(1)
        go func(b uint16) {
            defer wg.Done()
            docs := redis.SMembers("block:" + strconv.Itoa(int(b)))
            for _, doc := range docs {
                candidates[doc] = true
            }
        }(block)
    }
    wg.Wait()

    return mapToSlice(candidates)
}
```

**2. 预计算：**
```go
// 预计算MinHash签名
type PrecomputedDoc struct {
    ID       string
    MinHash  []uint32
    SimHash  uint64
}

// 定期更新预计算结果
func UpdatePrecomputed() {
    docs := getAllDocuments()
    for _, doc := range docs {
        mh := MinHash(doc.Content, 128)
        sh := SimHash(doc.Content)
        savePrecomputed(doc.ID, mh, sh)
    }
}
```

**3. 热点数据预热：**
```go
// 启动时预热热点数据
func WarmUp() {
    hotDocs := getHotDocuments(10000)
    for _, doc := range hotDocs {
        localCache.Add(doc.ID, doc)
    }
}
```

**性能指标：**
- P50: 30ms
- P95: 50ms
- P99: 80ms

**187. Redis Cluster如何做海量指纹索引？**

**答案：**
**分片策略：**
```go
// 1024个分片
func GetShard(fingerprint uint64) int {
    return int(fingerprint % 1024)
}

// 写入
func AddFingerprint(docID string, fingerprint uint64) {
    shard := GetShard(fingerprint)
    key := fmt.Sprintf("shard:%d:fp:%d", shard, fingerprint)
    redis.SAdd(key, docID)

    // 分块索引
    blocks := GetBlockIndexes(fingerprint)
    for _, block := range blocks {
        blockKey := fmt.Sprintf("shard:%d:block:%d", shard, block)
        redis.SAdd(blockKey, docID)
    }
}

// 查询
func QueryFingerprint(fingerprint uint64) []string {
    shard := GetShard(fingerprint)
    blocks := GetBlockIndexes(fingerprint)

    candidates := make(map[string]bool)
    for _, block := range blocks {
        blockKey := fmt.Sprintf("shard:%d:block:%d", shard, block)
        docs, _ := redis.SMembers(blockKey).Result()
        for _, doc := range docs {
            candidates[doc] = true
        }
    }

    return mapToSlice(candidates)
}
```

**容量规划：**
```
10亿文档 × 64位指纹 = 8GB
分块索引(4块) × 10亿 × 8字节 = 32GB
总计：约40GB

1024分片 → 每分片40MB
```

**188. 如何将召回率从85%提升至99%？**

**答案：**
**优化措施：**

**1. 降低阈值：**
```go
// SimHash海明距离阈值从3提高到5
const hammingThreshold = 5
```

**2. 多特征融合：**
```go
func MultiFeatureMatch(doc1, doc2 Document) bool {
    // 特征1：SimHash
    if HammingDistance(doc1.SimHash, doc2.SimHash) <= 5 {
        return true
    }

    // 特征2：MinHash
    if MinHashSimilarity(doc1.MinHash, doc2.MinHash) > 0.7 {
        return true
    }

    // 特征3：关键词重叠
    if KeywordOverlap(doc1.Keywords, doc2.Keywords) > 0.6 {
        return true
    }

    return false
}
```

**3. 分段匹配：**
```go
// 长文本分段处理
func SegmentMatch(text string) []string {
    segments := splitText(text, 500)  // 每500字一段
    allMatches := make(map[string]bool)

    for _, seg := range segments {
        matches := Query(seg)
        for _, m := range matches {
            allMatches[m] = true
        }
    }

    return mapToSlice(allMatches)
}
```

**4. 机器学习模型：**
```go
// 使用训练好的模型进行二次排序
func MLRanking(candidates []string, query string) []string {
    scores := make([]float64, len(candidates))

    for i, docID := range candidates {
        doc := getDocument(docID)
        features := extractFeatures(query, doc)
        scores[i] = model.Predict(features)
    }

    // 按分数排序
    sort.Slice(candidates, func(i, j int) bool {
        return scores[i] > scores[j]
    })

    return candidates
}
```

**效果对比：**
| 优化阶段 | 召回率 | 准确率 |
|---------|--------|--------|
| 初始版本 | 85% | 90% |
| +多特征 | 92% | 88% |
| +分段匹配 | 96% | 85% |
| +ML模型 | 99% | 92% |

**189. 如何保证系统的可扩展性？**

**答案：**
**架构设计：**
```
负载均衡 → API网关 → 微服务集群
                    ├─ 特征提取服务(可扩展)
                    ├─ 指纹生成服务(可扩展)
                    ├─ 查询服务(可扩展)
                    └─ 计算服务(可扩展)
                           ↓
                    Redis Cluster(可扩展)
```

**水平扩展：**
```go
// 服务注册与发现
func RegisterService(serviceName, addr string) {
    consul.Register(serviceName, addr)
}

// 负载均衡
func GetService(serviceName string) string {
    services := consul.GetServices(serviceName)
    return loadBalance(services)  // 轮询/随机/最少连接
}
```

**数据分片：**
```go
// 一致性哈希
type ConsistentHash struct {
    ring map[uint32]string
    sortedKeys []uint32
}

func (ch *ConsistentHash) AddNode(node string) {
    for i := 0; i < 150; i++ {  // 150个虚拟节点
        hash := hashKey(node + strconv.Itoa(i))
        ch.ring[hash] = node
        ch.sortedKeys = append(ch.sortedKeys, hash)
    }
    sort.Slice(ch.sortedKeys, func(i, j int) bool {
        return ch.sortedKeys[i] < ch.sortedKeys[j]
    })
}

func (ch *ConsistentHash) GetNode(key string) string {
    hash := hashKey(key)
    idx := sort.Search(len(ch.sortedKeys), func(i int) bool {
        return ch.sortedKeys[i] >= hash
    })
    if idx == len(ch.sortedKeys) {
        idx = 0
    }
    return ch.ring[ch.sortedKeys[idx]]
}
```

## 2. 内容审核平台2.0

**190-197. 审核平台相关问题**

**核心设计：**
- 可配置化规则引擎
- 拖拽式流程编排
- 微服务架构
- Kafka消息队列
- Goroutine池处理

**关键技术点：**
1. 规则引擎（Rete算法）
2. 工作流引擎
3. 任务分发算法
4. 实时监控告警

## 3. 百度房抵贷系统

**198-204. 房抵贷系统相关问题**

**核心功能：**
- 分布式事务（TCC）
- 工单流转系统
- 风控规则引擎
- 数据加密传输
- 等保三级认证

## 4. 棋牌游戏系统

**205-210. 游戏系统相关问题**

**核心技术：**
- 房间匹配算法
- 状态同步机制
- WebSocket长连接
- 防作弊机制
- 灰度发布

---

**注：以上项目经验问题的详细答案需要结合实际项目情况回答，重点突出：**
1. 技术选型理由
2. 架构设计思路
3. 性能优化方案
4. 遇到的挑战和解决方案
5. 量化的业务成果
