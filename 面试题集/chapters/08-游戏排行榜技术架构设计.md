# 游戏排行榜技术架构设计

## 一、业务需求分析

### 1.1 核心功能需求
- **实时排名查询**：玩家查询自己和他人的排名
- **排行榜展示**：展示Top N玩家列表
- **分数更新**：玩家分数实时更新并反映到排行榜
- **多维度排行**：支持多种排行榜类型（日榜、周榜、月榜、总榜等）
- **分页查询**：支持排行榜分页浏览

### 1.2 性能需求
- **查询响应时间**：< 100ms
- **更新延迟**：< 1s
- **并发支持**：支持高并发读写
- **数据一致性**：最终一致性即可

### 1.3 技术挑战
- **大数据量场景**：百万、千万级用户排名计算
- **高并发读写**：游戏高峰期的并发压力
- **实时性要求**：分数更新后快速反映到排行榜
- **多维度排序**：不同时间维度、不同类型的排行榜

---

## 二、小数据量场景架构（< 10万用户）

### 2.1 技术选型

#### 核心存储：MySQL
```sql
CREATE TABLE leaderboard (
    user_id BIGINT PRIMARY KEY,
    username VARCHAR(50),
    score BIGINT NOT NULL,
    update_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_score (score DESC, user_id)
) ENGINE=InnoDB;
```

#### 缓存层：Redis
```redis
# 使用Sorted Set存储排行榜
ZADD leaderboard:daily {score} {user_id}
```

### 2.2 架构设计

```
┌─────────────┐
│   Client    │
└──────┬──────┘
       │
       ▼
┌─────────────────┐
│  API Gateway    │
└──────┬──────────┘
       │
       ▼
┌─────────────────┐
│ Leaderboard     │
│   Service       │
└──────┬──────────┘
       │
       ├──────────┐
       ▼          ▼
┌──────────┐  ┌──────────┐
│  Redis   │  │  MySQL   │
│ (Cache)  │  │ (Master) │
└──────────┘  └──────────┘
```

### 2.3 核心实现

#### 2.3.1 分数更新
```go
func UpdateScore(userID int64, score int64) error {
    // 1. 更新MySQL
    err := db.Exec("UPDATE leaderboard SET score = ? WHERE user_id = ?", score, userID)
    if err != nil {
        return err
    }

    // 2. 更新Redis
    err = redis.ZAdd("leaderboard:daily", score, userID)
    if err != nil {
        log.Error("Redis update failed", err)
        // 不影响主流程，异步重试
    }

    return nil
}
```

#### 2.3.2 查询排名
```go
func GetUserRank(userID int64) (int64, error) {
    // 优先从Redis查询
    rank, err := redis.ZRevRank("leaderboard:daily", userID)
    if err == nil {
        return rank + 1, nil // Redis排名从0开始
    }

    // Redis失败，降级到MySQL
    var rank int64
    err = db.QueryRow(`
        SELECT COUNT(*) + 1
        FROM leaderboard
        WHERE score > (SELECT score FROM leaderboard WHERE user_id = ?)
    `, userID).Scan(&rank)

    return rank, err
}
```

#### 2.3.3 获取Top N
```go
func GetTopN(n int) ([]User, error) {
    // 从Redis获取
    userIDs, err := redis.ZRevRange("leaderboard:daily", 0, n-1)
    if err != nil {
        return nil, err
    }

    // 批量查询用户信息
    users, err := db.Query(`
        SELECT user_id, username, score
        FROM leaderboard
        WHERE user_id IN (?)
        ORDER BY score DESC
    `, userIDs)

    return users, err
}
```

### 2.4 优化策略

#### 2.4.1 缓存预热
```go
func WarmupCache() error {
    // 启动时将MySQL数据加载到Redis
    rows, err := db.Query("SELECT user_id, score FROM leaderboard ORDER BY score DESC LIMIT 10000")
    if err != nil {
        return err
    }

    pipe := redis.Pipeline()
    for rows.Next() {
        var userID, score int64
        rows.Scan(&userID, &score)
        pipe.ZAdd("leaderboard:daily", score, userID)
    }

    return pipe.Exec()
}
```

#### 2.4.2 定时同步
```go
func SyncToMySQL() {
    ticker := time.NewTicker(5 * time.Minute)
    for range ticker.C {
        // 从Redis同步到MySQL
        members, _ := redis.ZRevRangeWithScores("leaderboard:daily", 0, -1)

        tx, _ := db.Begin()
        for _, member := range members {
            tx.Exec("UPDATE leaderboard SET score = ? WHERE user_id = ?",
                member.Score, member.Member)
        }
        tx.Commit()
    }
}
```

---

## 三、大数据量场景架构（> 100万用户）

### 3.1 技术选型

#### 核心存储：Redis Cluster + MySQL分库分表
#### 计算引擎：Flink/Spark Streaming
#### 消息队列：Kafka

### 3.2 架构设计

```
┌─────────────┐
│   Client    │
└──────┬──────┘
       │
       ▼
┌─────────────────┐
│  API Gateway    │
│   (Nginx/Kong)  │
└──────┬──────────┘
       │
       ▼
┌─────────────────┐
│ Leaderboard     │
│   Service       │
│  (微服务集群)    │
└──────┬──────────┘
       │
       ├──────────────┬──────────────┐
       ▼              ▼              ▼
┌──────────┐   ┌──────────┐   ┌──────────┐
│  Redis   │   │  Kafka   │   │  MySQL   │
│ Cluster  │   │          │   │ Sharding │
└──────────┘   └────┬─────┘   └──────────┘
                    │
                    ▼
              ┌──────────┐
              │  Flink   │
              │ Streaming│
              └──────────┘
```

### 3.3 核心实现

#### 3.3.1 分库分表策略

```go
// 按user_id取模分表
func GetShardTable(userID int64) string {
    shardNum := userID % 256
    return fmt.Sprintf("leaderboard_%03d", shardNum)
}

// 分库策略
func GetShardDB(userID int64) *sql.DB {
    dbNum := (userID / 256) % 8
    return dbPool[dbNum]
}
```

#### 3.3.2 Redis Cluster分片

```go
// 使用一致性哈希分片
type LeaderboardCache struct {
    cluster *redis.ClusterClient
}

func (c *LeaderboardCache) UpdateScore(leaderboardType string, userID int64, score int64) error {
    key := fmt.Sprintf("leaderboard:%s", leaderboardType)
    return c.cluster.ZAdd(context.Background(), key, &redis.Z{
        Score:  float64(score),
        Member: userID,
    }).Err()
}

// 分段存储大排行榜
func (c *LeaderboardCache) UpdateScoreSegmented(userID int64, score int64) error {
    // 按分数段分片，减少单个Sorted Set大小
    segment := score / 10000
    key := fmt.Sprintf("leaderboard:daily:seg_%d", segment)
    return c.cluster.ZAdd(context.Background(), key, &redis.Z{
        Score:  float64(score),
        Member: userID,
    }).Err()
}
```

#### 3.3.3 异步更新架构

```go
// 分数更新通过消息队列异步处理
func UpdateScoreAsync(userID int64, score int64) error {
    msg := ScoreUpdateMessage{
        UserID:    userID,
        Score:     score,
        Timestamp: time.Now().Unix(),
    }

    // 发送到Kafka
    return kafka.Produce("score-updates", msg)
}

// Kafka消费者批量处理
func ConsumeScoreUpdates() {
    consumer := kafka.NewConsumer("score-updates")

    for {
        messages := consumer.ConsumeBatch(1000, 100*time.Millisecond)

        // 批量更新Redis
        pipe := redis.Pipeline()
        for _, msg := range messages {
            pipe.ZAdd("leaderboard:daily", msg.Score, msg.UserID)
        }
        pipe.Exec()

        // 异步持久化到MySQL
        go persistToMySQL(messages)
    }
}
```

#### 3.3.4 实时计算排名（Flink）

```java
// Flink实时计算排行榜
public class LeaderboardCalculator {
    public static void main(String[] args) {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        // 从Kafka读取分数更新
        FlinkKafkaConsumer<ScoreUpdate> consumer = new FlinkKafkaConsumer<>(
            "score-updates",
            new ScoreUpdateSchema(),
            properties
        );

        DataStream<ScoreUpdate> updates = env.addSource(consumer);

        // 按时间窗口聚合
        updates
            .keyBy(ScoreUpdate::getUserId)
            .window(TumblingEventTimeWindows.of(Time.seconds(10)))
            .aggregate(new ScoreAggregator())
            .addSink(new RedisSink()); // 写入Redis

        env.execute("Leaderboard Calculator");
    }
}
```

### 3.4 查询优化

#### 3.4.1 多级缓存

```go
type LeaderboardService struct {
    localCache  *cache.Cache      // 本地缓存（1分钟）
    redisCache  *redis.Client     // Redis缓存
    db          *sql.DB           // MySQL
}

func (s *LeaderboardService) GetTopN(n int) ([]User, error) {
    // L1: 本地缓存
    if users, found := s.localCache.Get("top_" + strconv.Itoa(n)); found {
        return users.([]User), nil
    }

    // L2: Redis缓存
    userIDs, err := s.redisCache.ZRevRange("leaderboard:daily", 0, int64(n-1)).Result()
    if err == nil && len(userIDs) > 0 {
        users := s.batchGetUsers(userIDs)
        s.localCache.Set("top_" + strconv.Itoa(n), users, 1*time.Minute)
        return users, nil
    }

    // L3: MySQL降级
    return s.getTopNFromDB(n)
}
```

#### 3.4.2 排名近似计算

```go
// 对于非Top玩家，使用近似排名
func (s *LeaderboardService) GetApproximateRank(userID int64, score int64) (int64, error) {
    // 1. 精确计算Top 10000
    if rank, err := s.redisCache.ZRevRank("leaderboard:daily", userID).Result(); err == nil {
        if rank < 10000 {
            return rank + 1, nil
        }
    }

    // 2. 使用HyperLogLog估算总人数
    totalUsers, _ := s.redisCache.PFCount("leaderboard:users").Result()

    // 3. 使用分数段估算排名
    higherScoreCount, _ := s.redisCache.ZCount("leaderboard:daily",
        fmt.Sprintf("(%d", score), "+inf").Result()

    return higherScoreCount + 1, nil
}
```

#### 3.4.3 预计算Top榜单

```go
// 定时预计算并缓存热门榜单
func PrecomputeLeaderboards() {
    ticker := time.NewTicker(1 * time.Minute)

    for range ticker.C {
        // 计算Top 100
        top100, _ := redis.ZRevRangeWithScores("leaderboard:daily", 0, 99)

        // 序列化并缓存
        data, _ := json.Marshal(top100)
        redis.Set("leaderboard:top100:cache", data, 2*time.Minute)

        // 同样处理周榜、月榜等
        precomputeWeeklyLeaderboard()
        precomputeMonthlyLeaderboard()
    }
}
```

---

## 四、多维度排行榜设计

### 4.1 时间维度

```go
type LeaderboardManager struct {
    redis *redis.Client
}

// 日榜
func (m *LeaderboardManager) GetDailyKey() string {
    return fmt.Sprintf("leaderboard:daily:%s", time.Now().Format("20060102"))
}

// 周榜
func (m *LeaderboardManager) GetWeeklyKey() string {
    year, week := time.Now().ISOWeek()
    return fmt.Sprintf("leaderboard:weekly:%d_W%02d", year, week)
}

// 月榜
func (m *LeaderboardManager) GetMonthlyKey() string {
    return fmt.Sprintf("leaderboard:monthly:%s", time.Now().Format("200601"))
}

// 更新所有维度
func (m *LeaderboardManager) UpdateAllDimensions(userID int64, score int64) error {
    pipe := m.redis.Pipeline()

    // 更新日榜
    pipe.ZIncrBy(m.GetDailyKey(), float64(score), fmt.Sprint(userID))
    pipe.Expire(m.GetDailyKey(), 48*time.Hour)

    // 更新周榜
    pipe.ZIncrBy(m.GetWeeklyKey(), float64(score), fmt.Sprint(userID))
    pipe.Expire(m.GetWeeklyKey(), 14*24*time.Hour)

    // 更新月榜
    pipe.ZIncrBy(m.GetMonthlyKey(), float64(score), fmt.Sprint(userID))
    pipe.Expire(m.GetMonthlyKey(), 60*24*time.Hour)

    // 更新总榜
    pipe.ZIncrBy("leaderboard:all_time", float64(score), fmt.Sprint(userID))

    _, err := pipe.Exec()
    return err
}
```

### 4.2 定时任务清理

```go
func CleanupExpiredLeaderboards() {
    ticker := time.NewTicker(1 * time.Hour)

    for range ticker.C {
        // 清理过期的日榜
        yesterday := time.Now().AddDate(0, 0, -2).Format("20060102")
        redis.Del(fmt.Sprintf("leaderboard:daily:%s", yesterday))

        // 清理过期的周榜
        lastWeek := time.Now().AddDate(0, 0, -14)
        year, week := lastWeek.ISOWeek()
        redis.Del(fmt.Sprintf("leaderboard:weekly:%d_W%02d", year, week))
    }
}
```

---

## 五、高可用与容灾

### 5.1 Redis高可用

```yaml
# Redis Sentinel配置
sentinel monitor leaderboard-master 127.0.0.1 6379 2
sentinel down-after-milliseconds leaderboard-master 5000
sentinel parallel-syncs leaderboard-master 1
sentinel failover-timeout leaderboard-master 10000
```

```go
// 使用Sentinel客户端
func NewRedisClient() *redis.Client {
    return redis.NewFailoverClient(&redis.FailoverOptions{
        MasterName:    "leaderboard-master",
        SentinelAddrs: []string{"sentinel1:26379", "sentinel2:26379", "sentinel3:26379"},
    })
}
```

### 5.2 降级策略

```go
func (s *LeaderboardService) GetTopNWithFallback(n int) ([]User, error) {
    // 尝试从Redis获取
    users, err := s.getTopNFromRedis(n)
    if err == nil {
        return users, nil
    }

    // Redis失败，降级到MySQL
    log.Warn("Redis failed, fallback to MySQL")
    users, err = s.getTopNFromMySQL(n)
    if err == nil {
        return users, nil
    }

    // MySQL也失败，返回缓存的静态数据
    log.Error("MySQL failed, return static cache")
    return s.getStaticCache(n), nil
}
```

### 5.3 限流保护

```go
import "golang.org/x/time/rate"

type RateLimitedService struct {
    limiter *rate.Limiter
    service *LeaderboardService
}

func (s *RateLimitedService) GetUserRank(userID int64) (int64, error) {
    if !s.limiter.Allow() {
        return 0, errors.New("rate limit exceeded")
    }
    return s.service.GetUserRank(userID)
}
```

---

## 六、性能优化总结

### 6.1 小数据量场景（< 10万）
- **存储**：MySQL + Redis
- **查询延迟**：< 10ms
- **更新延迟**：< 50ms
- **成本**：低

### 6.2 中等数据量场景（10万 - 100万）
- **存储**：MySQL分表 + Redis Cluster
- **查询延迟**：< 50ms
- **更新延迟**：< 100ms
- **成本**：中等

### 6.3 大数据量场景（> 100万）
- **存储**：MySQL分库分表 + Redis Cluster + Kafka + Flink
- **查询延迟**：< 100ms（Top榜）、< 500ms（普通排名）
- **更新延迟**：< 1s
- **成本**：高

---

## 七、监控与告警

### 7.1 关键指标

```go
// Prometheus指标
var (
    rankQueryDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "leaderboard_rank_query_duration_seconds",
            Help: "Rank query duration",
        },
        []string{"type"},
    )

    scoreUpdateCounter = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "leaderboard_score_updates_total",
            Help: "Total score updates",
        },
        []string{"status"},
    )
)

func (s *LeaderboardService) GetUserRankWithMetrics(userID int64) (int64, error) {
    start := time.Now()
    defer func() {
        rankQueryDuration.WithLabelValues("user").Observe(time.Since(start).Seconds())
    }()

    rank, err := s.GetUserRank(userID)
    if err != nil {
        scoreUpdateCounter.WithLabelValues("error").Inc()
        return 0, err
    }

    scoreUpdateCounter.WithLabelValues("success").Inc()
    return rank, nil
}
```

### 7.2 告警规则

```yaml
groups:
  - name: leaderboard
    rules:
      - alert: HighQueryLatency
        expr: histogram_quantile(0.99, leaderboard_rank_query_duration_seconds) > 0.5
        for: 5m
        annotations:
          summary: "Leaderboard query latency is high"

      - alert: RedisDown
        expr: up{job="redis"} == 0
        for: 1m
        annotations:
          summary: "Redis is down"
```

---

## 八、完整示例代码

### 8.1 Go实现

```go
package leaderboard

import (
    "context"
    "database/sql"
    "fmt"
    "time"

    "github.com/go-redis/redis/v8"
)

type Service struct {
    redis *redis.Client
    db    *sql.DB
}

func NewService(redisAddr string, db *sql.DB) *Service {
    rdb := redis.NewClient(&redis.Options{
        Addr: redisAddr,
    })

    return &Service{
        redis: rdb,
        db:    db,
    }
}

// 更新分数
func (s *Service) UpdateScore(ctx context.Context, userID int64, score int64) error {
    key := fmt.Sprintf("leaderboard:daily:%s", time.Now().Format("20060102"))

    // 更新Redis
    err := s.redis.ZAdd(ctx, key, &redis.Z{
        Score:  float64(score),
        Member: userID,
    }).Err()
    if err != nil {
        return fmt.Errorf("redis update failed: %w", err)
    }

    // 异步更新MySQL
    go func() {
        _, err := s.db.Exec("INSERT INTO leaderboard (user_id, score) VALUES (?, ?) "+
            "ON DUPLICATE KEY UPDATE score = ?", userID, score, score)
        if err != nil {
            // 记录日志，后续重试
            fmt.Printf("MySQL update failed: %v\n", err)
        }
    }()

    return nil
}

// 获取用户排名
func (s *Service) GetUserRank(ctx context.Context, userID int64) (int64, error) {
    key := fmt.Sprintf("leaderboard:daily:%s", time.Now().Format("20060102"))

    rank, err := s.redis.ZRevRank(ctx, key, fmt.Sprint(userID)).Result()
    if err != nil {
        return 0, fmt.Errorf("get rank failed: %w", err)
    }

    return rank + 1, nil
}

// 获取Top N
func (s *Service) GetTopN(ctx context.Context, n int) ([]UserScore, error) {
    key := fmt.Sprintf("leaderboard:daily:%s", time.Now().Format("20060102"))

    results, err := s.redis.ZRevRangeWithScores(ctx, key, 0, int64(n-1)).Result()
    if err != nil {
        return nil, fmt.Errorf("get top n failed: %w", err)
    }

    users := make([]UserScore, len(results))
    for i, z := range results {
        users[i] = UserScore{
            UserID: z.Member.(string),
            Score:  int64(z.Score),
            Rank:   int64(i + 1),
        }
    }

    return users, nil
}

type UserScore struct {
    UserID string
    Score  int64
    Rank   int64
}
```

---

## 九、总结

### 9.1 技术选型对比

| 场景 | 用户量 | 存储方案 | 查询延迟 | 更新延迟 | 复杂度 | 成本 |
|------|--------|----------|----------|----------|--------|------|
| 小型 | < 10万 | MySQL + Redis | < 10ms | < 50ms | 低 | 低 |
| 中型 | 10-100万 | MySQL分表 + Redis Cluster | < 50ms | < 100ms | 中 | 中 |
| 大型 | > 100万 | 分库分表 + Redis + Kafka + Flink | < 100ms | < 1s | 高 | 高 |

### 9.2 关键要点

1. **小数据量**：MySQL + Redis足够，简单高效
2. **大数据量**：需要分布式架构，异步处理，多级缓存
3. **实时性**：通过Redis Sorted Set实现毫秒级查询
4. **一致性**：采用最终一致性，异步同步到持久化存储
5. **高可用**：Redis Sentinel/Cluster + MySQL主从 + 降级策略
6. **性能优化**：多级缓存、预计算、分段存储、近似计算

### 9.3 最佳实践

- 根据实际用户量选择合适的架构，避免过度设计
- 优先保证读性能，写操作可以异步处理
- 使用Redis Sorted Set作为核心数据结构
- 实现完善的降级和容灾机制
- 做好监控和告警，及时发现问题
