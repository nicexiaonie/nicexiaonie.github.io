[toc]

## 三、数据库技术

### 1. MySQL核心

**61. MySQL的索引类型有哪些？各自的特点？**

**答案：**
**按数据结构分类：**
1. **B+树索引**（默认）：
   - 适用于范围查询、排序
   - 支持最左前缀原则
   - InnoDB和MyISAM都支持

2. **Hash索引**：
   - 只支持等值查询
   - 不支持范围查询和排序
   - Memory引擎支持

3. **全文索引（FULLTEXT）**：
   - 用于全文搜索
   - MyISAM和InnoDB（5.6+）支持

4. **空间索引（R-Tree）**：
   - 用于地理空间数据
   - MyISAM支持

**按逻辑分类：**
1. **主键索引（PRIMARY KEY）**：
   - 唯一且非空
   - 一个表只能有一个

2. **唯一索引（UNIQUE）**：
   - 值唯一，可以为NULL
   - 可以有多个

3. **普通索引（INDEX）**：
   - 最基本的索引
   - 无唯一性限制

4. **联合索引**：
   - 多个列组成的索引
   - 遵循最左前缀原则

**62. B+树索引的原理？为什么MySQL选择B+树而不是B树？**

**答案：**
**B+树特点：**
1. 所有数据存储在叶子节点
2. 叶子节点通过指针连接（链表）
3. 非叶子节点只存储索引
4. 所有叶子节点在同一层

**B+树 vs B树：**
| 特性 | B+树 | B树 |
|------|------|------|
| 数据位置 | 只在叶子节点 | 所有节点 |
| 范围查询 | 高效（链表） | 需要中序遍历 |
| 磁盘IO | 更少 | 更多 |
| 单次查询 | 稳定 | 不稳定 |

**为什么选择B+树：**
1. **范围查询高效**：叶子节点链表，顺序扫描
2. **磁盘IO少**：非叶子节点不存数据，一次读取更多索引
3. **查询稳定**：所有查询都到叶子节点，性能稳定
4. **支持顺序访问**：适合数据库的顺序读取

**示例：**
```
        [10, 20]
       /    |    \
    [5]  [15]  [25]
    /      |      \
[1,5] [10,15] [20,25,30]  ← 叶子节点（链表连接）
```

**63. 聚簇索引和非聚簇索引的区别？**

**答案：**
**聚簇索引（Clustered Index）：**
- 数据行和索引存储在一起
- InnoDB的主键索引
- 一个表只能有一个
- 叶子节点存储完整数据行

**非聚簇索引（Secondary Index）：**
- 索引和数据分开存储
- 叶子节点存储主键值
- 一个表可以有多个
- 需要回表查询

**查询过程：**
```sql
-- 主键查询（聚簇索引）
SELECT * FROM user WHERE id = 1;
-- 直接从聚簇索引获取数据

-- 普通索引查询（非聚簇索引）
SELECT * FROM user WHERE name = 'John';
-- 1. 从name索引找到主键id
-- 2. 回表：用id从聚簇索引获取完整数据
```

**区别总结：**
| 特性 | 聚簇索引 | 非聚簇索引 |
|------|----------|------------|
| 数据存储 | 索引和数据一起 | 分开存储 |
| 数量 | 1个 | 多个 |
| 查询性能 | 快（无需回表） | 慢（需要回表） |
| 插入性能 | 慢（需要维护顺序） | 快 |

**64. 联合索引的最左前缀原则？**

**答案：**
**原理：**
联合索引(a, b, c)相当于创建了(a)、(a,b)、(a,b,c)三个索引。

**示例：**
```sql
-- 创建联合索引
CREATE INDEX idx_abc ON user(a, b, c);

-- 可以使用索引
SELECT * FROM user WHERE a = 1;
SELECT * FROM user WHERE a = 1 AND b = 2;
SELECT * FROM user WHERE a = 1 AND b = 2 AND c = 3;
SELECT * FROM user WHERE a = 1 AND c = 3;  -- 只用到a

-- 不能使用索引
SELECT * FROM user WHERE b = 2;
SELECT * FROM user WHERE c = 3;
SELECT * FROM user WHERE b = 2 AND c = 3;
```

**最佳实践：**
1. 将区分度高的列放在前面
2. 将经常查询的列放在前面
3. 考虑查询频率和选择性

**优化示例：**
```sql
-- 场景：经常查询 WHERE city = 'Beijing' AND age > 20
-- 优化：将city放前面（区分度高）
CREATE INDEX idx_city_age ON user(city, age);
```

**65. 如何分析慢查询？explain的各个字段含义？**

**答案：**
**开启慢查询日志：**
```sql
SET GLOBAL slow_query_log = 1;
SET GLOBAL long_query_time = 2;  -- 超过2秒记录
```

**EXPLAIN字段：**
```sql
EXPLAIN SELECT * FROM user WHERE age > 20;
```

| 字段 | 含义 |
|------|------|
| **id** | 查询序号，越大越先执行 |
| **select_type** | 查询类型（SIMPLE/PRIMARY/SUBQUERY等） |
| **table** | 表名 |
| **type** | 访问类型（性能从好到坏）：<br>system > const > eq_ref > ref > range > index > ALL |
| **possible_keys** | 可能使用的索引 |
| **key** | 实际使用的索引 |
| **key_len** | 索引长度 |
| **ref** | 索引的哪一列被使用 |
| **rows** | 扫描的行数（估算） |
| **Extra** | 额外信息 |

**type详解：**
- **system**：表只有一行
- **const**：主键或唯一索引等值查询
- **eq_ref**：唯一索引扫描
- **ref**：非唯一索引扫描
- **range**：范围扫描（BETWEEN、>、<）
- **index**：全索引扫描
- **ALL**：全表扫描（最差）

**Extra详解：**
- **Using index**：覆盖索引，无需回表（好）
- **Using where**：使用WHERE过滤
- **Using filesort**：文件排序（差）
- **Using temporary**：使用临时表（差）
- **Using index condition**：索引下推

**优化示例：**
```sql
-- 差：全表扫描
EXPLAIN SELECT * FROM user WHERE age > 20;
-- type: ALL, rows: 100000

-- 优化：添加索引
CREATE INDEX idx_age ON user(age);
-- type: range, rows: 5000

-- 更好：覆盖索引
EXPLAIN SELECT id, age FROM user WHERE age > 20;
-- Extra: Using index
```
**66. 索引失效的场景有哪些？**

**答案：**
```sql
-- 1. 使用函数或表达式
SELECT * FROM user WHERE YEAR(create_time) = 2024;  -- 失效
SELECT * FROM user WHERE create_time >= '2024-01-01';  -- 生效

-- 2. 隐式类型转换
SELECT * FROM user WHERE phone = 13800138000;  -- phone是varchar，失效
SELECT * FROM user WHERE phone = '13800138000';  -- 生效

-- 3. 使用NOT、!=、<>
SELECT * FROM user WHERE age != 20;  -- 失效

-- 4. LIKE以%开头
SELECT * FROM user WHERE name LIKE '%John';  -- 失效
SELECT * FROM user WHERE name LIKE 'John%';  -- 生效

-- 5. OR条件（部分列无索引）
SELECT * FROM user WHERE age = 20 OR address = 'Beijing';  -- address无索引，失效

-- 6. 联合索引不满足最左前缀
CREATE INDEX idx_abc ON user(a, b, c);
SELECT * FROM user WHERE b = 2;  -- 失效

-- 7. 范围查询后的列
SELECT * FROM user WHERE a = 1 AND b > 2 AND c = 3;  -- c索引失效

-- 8. IS NULL可能失效（取决于数据分布）
SELECT * FROM user WHERE age IS NULL;
```

**67. 覆盖索引是什么？有什么优势？**

**答案：**
**定义：**
查询的列都在索引中，无需回表查询。

**示例：**
```sql
-- 创建索引
CREATE INDEX idx_name_age ON user(name, age);

-- 覆盖索引（无需回表）
SELECT name, age FROM user WHERE name = 'John';
-- Extra: Using index

-- 非覆盖索引（需要回表）
SELECT * FROM user WHERE name = 'John';
-- Extra: NULL（需要回表获取其他列）
```

**优势：**
1. 减少IO：无需回表，只读索引
2. 提升性能：减少磁盘访问
3. 减少随机IO：索引是顺序存储

**应用场景：**
- 统计查询：`SELECT COUNT(*) FROM user WHERE age > 20`
- 分页查询：先查ID，再回表
```sql
-- 优化前
SELECT * FROM user ORDER BY create_time LIMIT 100000, 10;

-- 优化后（覆盖索引+延迟关联）
SELECT * FROM user a
INNER JOIN (
    SELECT id FROM user ORDER BY create_time LIMIT 100000, 10
) b ON a.id = b.id;
```

**68. MySQL的事务隔离级别？各自解决什么问题？**

**答案：**
| 隔离级别 | 脏读 | 不可重复读 | 幻读 |
|---------|------|-----------|------|
| READ UNCOMMITTED | ✓ | ✓ | ✓ |
| READ COMMITTED | ✗ | ✓ | ✓ |
| REPEATABLE READ（默认） | ✗ | ✗ | ✗ |
| SERIALIZABLE | ✗ | ✗ | ✗ |

**问题说明：**
1. **脏读**：读到未提交的数据
2. **不可重复读**：同一事务内多次读取结果不同（UPDATE）
3. **幻读**：同一事务内多次读取记录数不同（INSERT/DELETE）

**示例：**
```sql
-- 设置隔离级别
SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;

-- 查看隔离级别
SELECT @@transaction_isolation;
```

**REPEATABLE READ如何解决幻读：**
- 使用MVCC（快照读）
- 使用Next-Key Lock（当前读）

**69. MVCC的实现原理？**

**答案：**
**MVCC（多版本并发控制）：**
通过保存数据的多个版本，实现读写不阻塞。

**实现机制：**
1. **隐藏列**：
   - `DB_TRX_ID`：事务ID
   - `DB_ROLL_PTR`：回滚指针
   - `DB_ROW_ID`：隐藏主键

2. **Undo Log**：
   - 保存历史版本
   - 通过回滚指针形成版本链

3. **Read View**：
   - 记录活跃事务列表
   - 判断版本可见性

**可见性判断：**
```
if (trx_id < min_trx_id):  # 已提交
    可见
elif (trx_id > max_trx_id):  # 未开始
    不可见
elif (trx_id in active_trx_ids):  # 活跃中
    不可见
else:
    可见
```

**快照读 vs 当前读：**
- **快照读**：普通SELECT，读取快照版本
- **当前读**：SELECT FOR UPDATE、UPDATE、DELETE，读取最新版本并加锁

**70. 行锁、表锁、间隙锁的区别？**

**答案：**
**行锁（Record Lock）：**
```sql
-- 锁定单行
SELECT * FROM user WHERE id = 1 FOR UPDATE;
```

**表锁（Table Lock）：**
```sql
-- 锁定整张表
LOCK TABLES user WRITE;
UNLOCK TABLES;
```

**间隙锁（Gap Lock）：**
```sql
-- 锁定范围（防止幻读）
SELECT * FROM user WHERE age BETWEEN 20 AND 30 FOR UPDATE;
-- 锁定(20, 30)之间的间隙，防止插入
```

**Next-Key Lock：**
- 行锁 + 间隙锁
- 锁定记录及其前面的间隙
- REPEATABLE READ默认使用

**对比：**
| 锁类型 | 粒度 | 并发性 | 开销 |
|--------|------|--------|------|
| 表锁 | 表 | 低 | 小 |
| 行锁 | 行 | 高 | 大 |
| 间隙锁 | 范围 | 中 | 中 |

**71. 死锁如何产生？如何避免？**

**答案：**
**产生原因：**
```sql
-- 事务1
BEGIN;
UPDATE user SET name = 'A' WHERE id = 1;  -- 锁定id=1
UPDATE user SET name = 'B' WHERE id = 2;  -- 等待id=2

-- 事务2
BEGIN;
UPDATE user SET name = 'C' WHERE id = 2;  -- 锁定id=2
UPDATE user SET name = 'D' WHERE id = 1;  -- 等待id=1，死锁！
```

**避免方法：**
1. **按相同顺序访问资源**
2. **减少事务持有锁的时间**
3. **使用较低的隔离级别**
4. **添加合理的索引**
5. **大事务拆分为小事务**

**检测和处理：**
```sql
-- 查看死锁日志
SHOW ENGINE INNODB STATUS;

-- 设置死锁超时
SET innodb_lock_wait_timeout = 50;

-- InnoDB自动检测并回滚代价小的事务
```

**72. 主从复制的原理？有哪些复制方式？**

**答案：**
**复制原理：**
```
1. 主库写入binlog
2. 从库IO线程读取binlog → relay log
3. 从库SQL线程执行relay log
```

**复制方式：**
1. **异步复制（默认）**：
   - 主库不等从库确认
   - 性能最好，可能丢数据

2. **半同步复制**：
   - 至少一个从库确认后返回
   - 性能和可靠性平衡

3. **全同步复制**：
   - 所有从库确认后返回
   - 性能最差，可靠性最高

**配置：**
```sql
-- 主库
[mysqld]
server-id = 1
log-bin = mysql-bin
binlog-format = ROW

-- 从库
[mysqld]
server-id = 2
relay-log = relay-bin
read-only = 1
```

**73. 主从延迟如何解决？**

**答案：**
**原因：**
1. 从库性能差
2. 大事务执行慢
3. 网络延迟
4. 从库负载高

**解决方案：**
1. **并行复制**：
```sql
-- MySQL 5.7+
slave-parallel-type = LOGICAL_CLOCK
slave-parallel-workers = 4
```

2. **优化大事务**：
   - 拆分为小事务
   - 避免大批量操作

3. **升级硬件**：
   - 提升从库性能
   - 使用SSD

4. **读写分离优化**：
   - 强一致性读主库
   - 最终一致性读从库

5. **监控延迟**：
```sql
SHOW SLAVE STATUS\G
-- Seconds_Behind_Master: 延迟秒数
```

**74. 分库分表的策略？如何选择分片键？**

**答案：**
**分库分表策略：**
1. **垂直拆分**：
   - 按业务模块拆分
   - 用户库、订单库、商品库

2. **水平拆分**：
   - 按数据量拆分
   - user_0, user_1, user_2...

**分片算法：**
1. **范围分片**：
```sql
-- 按ID范围
0-100万 → db0
100万-200万 → db1
```

2. **哈希分片**：
```sql
-- 按user_id哈希
db_index = user_id % 4
```

3. **一致性哈希**：
   - 减少数据迁移
   - 适合动态扩容

**选择分片键：**
1. **高频查询字段**（如user_id）
2. **数据分布均匀**
3. **避免热点数据**
4. **业务相关性强**

**示例：**
```sql
-- 订单表按user_id分片
-- 查询某用户订单时，只需访问一个分片
SELECT * FROM order WHERE user_id = 123;
```

**75. 分库分表后如何处理跨库查询和事务？**

**答案：**
**跨库查询：**
1. **应用层聚合**：
```go
// 查询所有分片，应用层合并
results := []Result{}
for _, db := range dbs {
    result := db.Query("SELECT * FROM user WHERE age > 20")
    results = append(results, result...)
}
// 排序、分页
```

2. **数据冗余**：
   - 将常用字段冗余到同一库
   - 空间换时间

3. **搜索引擎**：
   - 使用Elasticsearch
   - 适合复杂查询

**跨库事务：**
1. **避免跨库事务**（最佳）：
   - 业务设计避免
   - 数据冗余

2. **分布式事务**：
   - 2PC/3PC
   - TCC
   - Saga

3. **最终一致性**：
   - 消息队列
   - 定时补偿

**76. MySQL的读写分离如何实现？**

**答案：**
**实现方式：**
1. **应用层**：
```go
// 写操作 → 主库
masterDB.Exec("INSERT INTO user ...")

// 读操作 → 从库
slaveDB.Query("SELECT * FROM user ...")
```

2. **中间件**：
   - MySQL Proxy
   - ProxySQL
   - MyCat

3. **ORM框架**：
```go
// GORM示例
db.Clauses(dbresolver.Write).Create(&user)  // 主库
db.Clauses(dbresolver.Read).Find(&users)    // 从库
```

**注意事项：**
1. **主从延迟**：写后立即读可能读不到
2. **强一致性场景读主库**
3. **负载均衡**：多个从库轮询

**77. 如何进行MySQL性能调优？**

**答案：**
**SQL优化：**
1. 添加索引
2. 避免全表扫描
3. 使用覆盖索引
4. 优化JOIN查询

**配置优化：**
```ini
# 缓冲池（内存的70-80%）
innodb_buffer_pool_size = 8G

# 日志文件
innodb_log_file_size = 512M

# 连接数
max_connections = 1000

# 查询缓存（5.7已废弃）
query_cache_size = 0
```

**架构优化：**
1. 读写分离
2. 分库分表
3. 缓存（Redis）
4. 异步处理

**监控指标：**
- QPS/TPS
- 慢查询数量
- 连接数
- 缓冲池命中率

**78. InnoDB和MyISAM的区别？**

**答案：**
| 特性 | InnoDB | MyISAM |
|------|--------|--------|
| 事务 | 支持 | 不支持 |
| 外键 | 支持 | 不支持 |
| 锁粒度 | 行锁 | 表锁 |
| MVCC | 支持 | 不支持 |
| 崩溃恢复 | 支持 | 不支持 |
| 全文索引 | 5.6+支持 | 支持 |
| 存储空间 | 大 | 小 |
| 适用场景 | 高并发写 | 高并发读 |

**选择建议：**
- **InnoDB**：默认选择，支持事务和行锁
- **MyISAM**：只读场景，已逐渐淘汰

### 2. Redis核心

**79. Redis的5种数据结构及其底层实现？**

**答案：**
| 数据结构 | 底层实现 | 使用场景 |
|---------|---------|---------|
| **String** | SDS（简单动态字符串） | 缓存、计数器、分布式锁 |
| **List** | quicklist（ziplist+linkedlist） | 消息队列、时间线 |
| **Hash** | ziplist或hashtable | 对象存储、购物车 |
| **Set** | intset或hashtable | 标签、共同好友 |
| **ZSet** | ziplist或skiplist+hashtable | 排行榜、延时队列 |

**底层实现详解：**
```bash
# String - SDS
struct sdshdr {
    int len;      # 已使用长度
    int free;     # 剩余空间
    char buf[];   # 字节数组
}

# List - quicklist
quicklist = ziplist节点的双向链表

# Hash - 两种编码
ziplist: 元素少时使用（节省内存）
hashtable: 元素多时使用（查询快）

# Set - 两种编码
intset: 全是整数且数量少
hashtable: 其他情况

# ZSet - 跳表
skiplist: 多层链表，查询O(logN)
hashtable: 快速查找score
```

**80. Redis的持久化方式？RDB和AOF的区别？**

**答案：**
**RDB（快照）：**
```bash
# 配置
save 900 1      # 900秒内至少1个key变化
save 300 10     # 300秒内至少10个key变化
save 60 10000   # 60秒内至少10000个key变化

# 手动触发
SAVE           # 阻塞
BGSAVE         # 后台fork子进程
```

**AOF（追加日志）：**
```bash
# 配置
appendonly yes
appendfsync everysec  # 每秒同步（推荐）
# appendfsync always  # 每次写入
# appendfsync no      # 由OS决定

# 重写
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
```

**对比：**
| 特性 | RDB | AOF |
|------|-----|-----|
| 文件大小 | 小 | 大 |
| 恢复速度 | 快 | 慢 |
| 数据完整性 | 可能丢失 | 更完整 |
| 性能影响 | fork时影响 | 持续写入 |

**混合持久化（4.0+）：**
```bash
aof-use-rdb-preamble yes
# AOF重写时，前半部分用RDB格式，后半部分用AOF格式
```

**81. Redis的过期策略和内存淘汰策略？**

**答案：**
**过期策略：**
1. **惰性删除**：访问时检查是否过期
2. **定期删除**：每100ms随机抽查，删除过期key

**内存淘汰策略：**
```bash
# 配置
maxmemory 2gb
maxmemory-policy allkeys-lru
```

| 策略 | 说明 |
|------|------|
| **noeviction** | 不淘汰，写入报错（默认） |
| **allkeys-lru** | 所有key中淘汰最少使用 |
| **allkeys-lfu** | 所有key中淘汰最少频率 |
| **allkeys-random** | 所有key中随机淘汰 |
| **volatile-lru** | 设置过期时间的key中LRU |
| **volatile-lfu** | 设置过期时间的key中LFU |
| **volatile-random** | 设置过期时间的key中随机 |
| **volatile-ttl** | 淘汰TTL最小的key |

**82. 如何实现分布式锁？需要注意哪些问题？**

**答案：**
**基础实现：**
```go
// 加锁
SET lock_key unique_value NX EX 30

// 解锁（Lua脚本保证原子性）
if redis.call("get", KEYS[1]) == ARGV[1] then
    return redis.call("del", KEYS[1])
else
    return 0
end
```

**完整实现：**
```go
func Lock(key, value string, expireTime int) bool {
    result := redis.SetNX(key, value, expireTime)
    return result == "OK"
}

func Unlock(key, value string) bool {
    script := `
        if redis.call("get", KEYS[1]) == ARGV[1] then
            return redis.call("del", KEYS[1])
        else
            return 0
        end
    `
    result := redis.Eval(script, []string{key}, value)
    return result == 1
}
```

**注意问题：**
1. **设置过期时间**：防止死锁
2. **唯一标识**：防止误删别人的锁
3. **原子操作**：使用Lua脚本
4. **锁续期**：长任务需要自动续期
5. **RedLock算法**：多节点保证可靠性

**Redisson实现（推荐）：**
```java
RLock lock = redisson.getLock("myLock");
lock.lock(30, TimeUnit.SECONDS);
try {
    // 业务逻辑
} finally {
    lock.unlock();
}
```

**83. Redis的事务机制？与关系型数据库事务的区别？**

**答案：**
**Redis事务：**
```bash
MULTI          # 开始事务
SET key1 val1
SET key2 val2
EXEC           # 执行事务
# 或 DISCARD  # 取消事务
```

**WATCH机制（乐观锁）：**
```bash
WATCH key1
MULTI
SET key1 newval
EXEC  # 如果key1被修改，事务失败
```

**与MySQL事务对比：**
| 特性 | Redis | MySQL |
|------|-------|-------|
| 原子性 | 部分支持 | 完全支持 |
| 隔离性 | 不支持 | 支持 |
| 持久性 | 取决于配置 | 支持 |
| 回滚 | 不支持 | 支持 |

**Redis事务特点：**
- 命令入队，EXEC时一次性执行
- 单个命令失败不影响其他命令
- 不支持回滚

**84. Redis的发布订阅模式？**

**答案：**
```bash
# 订阅
SUBSCRIBE channel1 channel2

# 发布
PUBLISH channel1 "hello"

# 模式订阅
PSUBSCRIBE news.*
```

**实现示例：**
```go
// 订阅者
pubsub := redis.Subscribe("channel1")
for msg := range pubsub.Channel() {
    fmt.Println(msg.Payload)
}

// 发布者
redis.Publish("channel1", "hello")
```

**缺点：**
- 消息不持久化
- 订阅者离线会丢失消息
- 不支持消息确认

**替代方案：**
- Stream（5.0+）：支持持久化和消费组
- 消息队列（Kafka、RabbitMQ）

**85. Redis Cluster的原理？如何实现数据分片？**

**答案：**
**架构：**
- 16384个哈希槽
- 每个节点负责一部分槽
- 无中心化架构

**数据分片：**
```bash
# 计算槽位
slot = CRC16(key) % 16384

# 节点分配
节点A: 0-5460
节点B: 5461-10922
节点C: 10923-16383
```

**重定向：**
```bash
# 客户端访问错误节点
GET key
-MOVED 3999 127.0.0.1:6381  # 重定向到正确节点
```

**故障转移：**
- 主节点故障，从节点自动提升
- 半数以上节点同意才能提升

**搭建集群：**
```bash
redis-cli --cluster create \
  127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 \
  127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 \
  --cluster-replicas 1
```

**86. 缓存穿透、缓存击穿、缓存雪崩的区别和解决方案？**

**答案：**
**缓存穿透：**
- **问题**：查询不存在的数据，缓存和DB都没有
- **解决**：
  1. 布隆过滤器
  2. 缓存空值（TTL短）
  3. 参数校验

**缓存击穿：**
- **问题**：热点key过期，大量请求打到DB
- **解决**：
  1. 热点key不过期
  2. 互斥锁
  3. 逻辑过期

```go
// 互斥锁
func GetWithMutex(key string) (string, error) {
    val := redis.Get(key)
    if val != "" {
        return val, nil
    }

    // 获取锁
    if redis.SetNX("lock:"+key, 1, 10) {
        defer redis.Del("lock:" + key)

        // 查询DB
        val = db.Query(key)
        redis.Set(key, val, 3600)
        return val, nil
    }

    // 等待后重试
    time.Sleep(50 * time.Millisecond)
    return GetWithMutex(key)
}
```

**缓存雪崩：**
- **问题**：大量key同时过期，DB压力骤增
- **解决**：
  1. 过期时间加随机值
  2. 多级缓存
  3. 限流降级

```go
// 随机过期时间
ttl := 3600 + rand.Intn(300)
redis.Set(key, val, ttl)
```

**87. 如何保证缓存和数据库的一致性？**

**答案：**
**策略对比：**
| 策略 | 优点 | 缺点 |
|------|------|------|
| 先更新DB，再删缓存 | 简单 | 短暂不一致 |
| 先删缓存，再更新DB | 实现简单 | 可能读到旧数据 |
| 延迟双删 | 一致性好 | 复杂度高 |

**推荐方案：先更新DB，再删缓存**
```go
func Update(key string, val string) error {
    // 1. 更新数据库
    err := db.Update(key, val)
    if err != nil {
        return err
    }

    // 2. 删除缓存
    redis.Del(key)

    // 3. 延迟再删一次（可选）
    time.AfterFunc(500*time.Millisecond, func() {
        redis.Del(key)
    })

    return nil
}
```

**最终一致性方案：**
1. **订阅binlog**：Canal监听MySQL变更，异步删除缓存
2. **消息队列**：更新DB后发消息，消费者删缓存
3. **定时同步**：定时任务同步数据

**88. Redis的单线程模型？为什么单线程还能这么快？**

**答案：**
**单线程模型：**
- 命令执行是单线程
- IO多路复用（epoll）
- 避免线程切换和锁竞争

**快的原因：**
1. **纯内存操作**
2. **IO多路复用**：一个线程处理多个连接
3. **高效数据结构**
4. **避免上下文切换**
5. **简单的协议**

**89. Redis 6.0的多线程是什么？**

**答案：**
**多线程IO：**
- 网络IO使用多线程
- 命令执行仍是单线程
- 提升网络IO性能

**配置：**
```bash
io-threads 4
io-threads-do-reads yes
```

**架构：**
```
客户端请求 → IO线程读取 → 主线程执行命令 → IO线程写回
```

**90. 如何使用Redis实现排行榜功能？**

**答案：**
```bash
# 添加分数
ZADD leaderboard 100 user1
ZADD leaderboard 200 user2
ZADD leaderboard 150 user3

# 增加分数
ZINCRBY leaderboard 10 user1

# 获取排名（从0开始）
ZREVRANK leaderboard user1

# 获取分数
ZSCORE leaderboard user1

# 获取TOP10
ZREVRANGE leaderboard 0 9 WITHSCORES

# 获取某个范围
ZREVRANGEBYSCORE leaderboard 200 100 WITHSCORES

# 获取某用户周围的排名
ZREVRANGE leaderboard (rank-5) (rank+5) WITHSCORES
```

**实现示例：**
```go
// 添加分数
redis.ZAdd("leaderboard", redis.Z{Score: 100, Member: "user1"})

// 获取TOP10
result := redis.ZRevRangeWithScores("leaderboard", 0, 9)
for _, z := range result {
    fmt.Printf("Rank: %s, Score: %f\n", z.Member, z.Score)
}
```

**91. 如何使用Redis实现限流？**

**答案：**
**1. 计数器（固定窗口）：**
```go
func RateLimit(key string, limit int) bool {
    count := redis.Incr(key)
    if count == 1 {
        redis.Expire(key, 60)  // 1分钟窗口
    }
    return count <= limit
}
```

**2. 滑动窗口（ZSet）：**
```go
func SlidingWindow(key string, limit int, window int) bool {
    now := time.Now().Unix()

    // 删除过期数据
    redis.ZRemRangeByScore(key, 0, now-window)

    // 统计当前窗口内的请求数
    count := redis.ZCard(key)
    if count < limit {
        redis.ZAdd(key, redis.Z{Score: float64(now), Member: now})
        redis.Expire(key, window)
        return true
    }
    return false
}
```

**3. 令牌桶（Lua脚本）：**
```lua
local key = KEYS[1]
local capacity = tonumber(ARGV[1])
local rate = tonumber(ARGV[2])
local now = tonumber(ARGV[3])

local tokens = redis.call('hget', key, 'tokens')
local last_time = redis.call('hget', key, 'last_time')

if tokens == false then
    tokens = capacity
    last_time = now
else
    tokens = tonumber(tokens)
    last_time = tonumber(last_time)

    local delta = math.max(0, now - last_time)
    tokens = math.min(capacity, tokens + delta * rate)
end

if tokens >= 1 then
    tokens = tokens - 1
    redis.call('hset', key, 'tokens', tokens)
    redis.call('hset', key, 'last_time', now)
    return 1
else
    return 0
end
```

**92. Redis的pipeline和事务的区别？**

**答案：**
**Pipeline：**
- 批量发送命令，减少网络往返
- 非原子性
- 提升性能

```go
pipe := redis.Pipeline()
pipe.Set("key1", "val1", 0)
pipe.Set("key2", "val2", 0)
pipe.Set("key3", "val3", 0)
_, err := pipe.Exec()
```

**事务：**
- 保证原子性
- MULTI/EXEC包裹
- 命令入队后一次性执行

```go
pipe := redis.TxPipeline()
pipe.Multi()
pipe.Set("key1", "val1", 0)
pipe.Set("key2", "val2", 0)
pipe.Exec()
```

**区别：**
| 特性 | Pipeline | 事务 |
|------|----------|------|
| 原子性 | 否 | 是 |
| 性能 | 更快 | 较快 |
| 用途 | 批量操作 | 原子操作 |
| 回滚 | 不支持 | 不支持 |

### 3. 其他数据库

**93. PostgreSQL相比MySQL有哪些优势？**

**答案：**
| 特性 | PostgreSQL | MySQL |
|------|-----------|-------|
| **SQL标准** | 更严格遵循 | 部分遵循 |
| **复杂查询** | 更强大 | 较弱 |
| **JSON支持** | 原生支持，功能强大 | 5.7+支持 |
| **全文检索** | 内置强大 | 较弱 |
| **窗口函数** | 完整支持 | 8.0+支持 |
| **并发控制** | MVCC更完善 | MVCC |
| **扩展性** | 插件丰富 | 较少 |
| **GIS支持** | PostGIS强大 | 基础支持 |

**PostgreSQL优势：**
1. **复杂查询**：CTE、窗口函数、递归查询
2. **数据类型丰富**：数组、JSON、UUID、范围类型
3. **扩展性强**：自定义函数、类型、索引
4. **ACID完整**：更严格的事务支持

**使用场景：**
- 复杂查询和分析
- GIS地理信息系统
- 需要严格ACID的场景
- 数据仓库

**94. MongoDB的使用场景？**

**答案：**
**特点：**
- 文档型数据库（JSON格式）
- 无Schema，灵活
- 水平扩展容易
- 查询性能好

**适用场景：**
1. **日志系统**：结构灵活，写入快
2. **内容管理**：文章、评论等非结构化数据
3. **用户画像**：字段不固定
4. **实时分析**：聚合查询强大
5. **物联网**：海量时序数据

**不适用场景：**
- 需要复杂事务
- 需要JOIN查询
- 强一致性要求高

**示例：**
```javascript
// 插入文档
db.users.insertOne({
    name: "John",
    age: 30,
    tags: ["developer", "golang"],
    address: {
        city: "Beijing",
        street: "Chaoyang"
    }
})

// 查询
db.users.find({ age: { $gt: 25 } })

// 聚合
db.users.aggregate([
    { $match: { age: { $gt: 25 } } },
    { $group: { _id: "$city", count: { $sum: 1 } } }
])
```

**95. Elasticsearch的倒排索引原理？**

**答案：**
**倒排索引：**
从词到文档的映射。

**正排索引 vs 倒排索引：**
```
正排索引（文档→词）：
Doc1: "hello world"
Doc2: "hello elasticsearch"

倒排索引（词→文档）：
hello: [Doc1, Doc2]
world: [Doc1]
elasticsearch: [Doc2]
```

**倒排索引结构：**
```
Term Dictionary（词典）
├─ hello → Posting List
├─ world → Posting List
└─ elasticsearch → Posting List

Posting List（倒排列表）
├─ DocID: 1, Position: [0], Frequency: 1
└─ DocID: 2, Position: [0], Frequency: 1
```

**查询流程：**
```
1. 分词：将查询文本分词
2. 查词典：找到对应的Posting List
3. 合并：多个词的结果求交集/并集
4. 排序：根据相关性评分排序
```

**优化技术：**
1. **Term Index**：FST结构，快速定位词
2. **压缩**：Frame of Reference压缩DocID
3. **跳表**：快速跳过不相关文档
4. **缓存**：查询结果缓存

**示例：**
```json
// 创建索引
PUT /articles
{
  "mappings": {
    "properties": {
      "title": { "type": "text" },
      "content": { "type": "text" }
    }
  }
}

// 搜索
GET /articles/_search
{
  "query": {
    "match": {
      "content": "elasticsearch"
    }
  }
}
```

---

